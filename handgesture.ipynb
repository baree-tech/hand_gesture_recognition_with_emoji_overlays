{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd90fc-8082-4436-81de-dcf2eab93a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Real Time Hand Gesture Recognition with Emoji Overlays (LIKE & VICTORY)\n",
    "## created by Bareera Mushthak\n",
    "\n",
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8520802-4262-4e08-961d-060bae236489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoWriter initialized successfully.\n",
      "Recording finished and saved as 'my_gesture_video.mp4'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747218238.861115   10497 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1747218238.861854   18118 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (ADL-S GT0.5)\n",
      "W0000 00:00:1747218238.869638   18109 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747218238.882601   18111 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Define functions\n",
    "\n",
    "def calculate_angle(a, b, c):  # to calculate thumb angle\n",
    "    \"\"\"Calculate angle between three points: a (start), b (mid), c (end)\"\"\"\n",
    "    ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) -\n",
    "                       math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    return abs(ang)\n",
    "\n",
    "    \n",
    "def resize_emoji(img, width=None, height=None):\n",
    "    \"\"\"Resize emoji image proportionally\"\"\"\n",
    "    if width is None and height is None:\n",
    "        return img\n",
    "    h, w = img.shape[:2]\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "    return cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    \n",
    "\n",
    "def overlay_image(bg, overlay, x, y):\n",
    "    \"\"\"Overlay emoji image with transparency and boundary check\"\"\"\n",
    "    h, w = overlay.shape[:2]\n",
    "    bg_h, bg_w = bg.shape[:2]\n",
    "\n",
    "    # Adjust width/height if overlay exceeds bg size\n",
    "    if y < 0:\n",
    "        overlay = overlay[-y:, :]\n",
    "        h = overlay.shape[0]\n",
    "        y = 0\n",
    "    if x < 0:\n",
    "        overlay = overlay[:, -x:]\n",
    "        w = overlay.shape[1]\n",
    "        x = 0\n",
    "    if y + h > bg_h:\n",
    "        h = bg_h - y\n",
    "        overlay = overlay[:h, :, :]\n",
    "    if x + w > bg_w:\n",
    "        w = bg_w - x\n",
    "        overlay = overlay[:, :w, :]\n",
    "\n",
    "    if overlay.shape[2] < 4:  # Ensure overlay has alpha channel\n",
    "        return\n",
    "\n",
    "    alpha = overlay[:, :, 3] / 255.0\n",
    "    for c in range(3):\n",
    "        bg[y:y+h, x:x+w, c] = (1 - alpha) * bg[y:y+h, x:x+w, c] + alpha * overlay[:, :, c]\n",
    "\n",
    "        \n",
    "# Initialize mediapipe\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "\n",
    "# Load emoji images\n",
    "\n",
    "like_img = cv2.imread('like.png', cv2.IMREAD_UNCHANGED)\n",
    "fireworks_img = cv2.imread('fireworks.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "# --- SETUP CAMERA ---\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width and height (optional, but helps avoid resizing issues)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Most compatible\n",
    "out = cv2.VideoWriter('my_gesture_video.avi', fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "if not out.isOpened():\n",
    "    print(\"Error: VideoWriter not initialized properly.\")\n",
    "else:\n",
    "    print(\"VideoWriter initialized successfully.\")\n",
    "\n",
    "\n",
    "print(\"Recording finished and saved as 'my_gesture_video.mp4'.\")\n",
    "fireworks_positions = []\n",
    "\n",
    "# --- RESIZE EMOJI BASED ON FRAME ---\n",
    "ret, test_frame = cap.read()\n",
    "if ret:\n",
    "    frame_h, frame_w = test_frame.shape[:2]\n",
    "    like_img = resize_emoji(like_img, width=int(frame_w * 0.15))  # Resize to 10% width\n",
    "else:\n",
    "    print(\"Failed to read from webcam\")\n",
    "\n",
    "# Define fingertios landmark indexes for finger (from Mediapipe hand model)\n",
    "tip_ids = [4, 8, 12, 16, 20]\n",
    "\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "        # FLip and convert color\n",
    "        image = cv2.flip(image, 1)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB )\n",
    "        results = hands.process(image_rgb)\n",
    "        finger_count = 0\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                lm_list = []\n",
    "\n",
    "                for id, lm in enumerate(hand_landmarks.landmark):\n",
    "                    h, w, _ = image.shape\n",
    "                    cx ,cy = int(lm.x * w), int(lm.y *h)\n",
    "                    lm_list.append((id, cx ,cy))\n",
    "                # check fingers are up (skip if not 21 landmarks)\n",
    "                                    # Assuming lm_list is already filled with (id, x, y)\n",
    "                if len(lm_list) != 0:\n",
    "                    fingers = []\n",
    "                    # Extract thumb base, joint, and tip\n",
    "                    a = lm_list[2][1:]  # Thumb base\n",
    "                    b = lm_list[3][1:]  # Thumb joint\n",
    "                    c = lm_list[4][1:]  # Thumb tip\n",
    "                    \n",
    "                    thumb_angle = calculate_angle(a, b, c)\n",
    "                    \n",
    "                    # Detect thumb \"up\" if angle is more than 150 degrees (almost straight)\n",
    "                    if thumb_angle > 150:\n",
    "                        fingers.append(1)\n",
    "                    else:\n",
    "                        fingers.append(0)\n",
    "\n",
    "                    # Optional: show angle on screen for tuning\n",
    "                    cv2.putText(image, f'Thumb Angle: {int(thumb_angle)}', (10, 430),\n",
    "                                cv2.FONT_HERSHEY_PLAIN, 1.2, (0, 255, 255), 1)\n",
    "                   \n",
    "                    # Other 4 fingers: check if tip is above lower joint in Y axis\n",
    "                    for id in range(1, 5):\n",
    "                        tip_y = lm_list[tip_ids[id]][2]\n",
    "                        joint_y = lm_list[tip_ids[id] - 2][2]\n",
    "                        if tip_y < joint_y:\n",
    "                            fingers.append(1)\n",
    "                        else:\n",
    "                            fingers.append(0)\n",
    "\n",
    "                    finger_count = fingers.count (1)\n",
    "\n",
    "                    # Show detected finger list on screen for debug\n",
    "                    cv2.putText(image, str(fingers), (20, 450),\n",
    "                               cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "                    # Like gesture detection (only thumb up)\n",
    "                    if fingers[0] == 1 and fingers[1:] == [0, 0, 0, 0]:\n",
    "                        cv2.putText(image, 'LIKE!', (60, 90),\n",
    "                                    cv2.FONT_HERSHEY_COMPLEX, 1, (200, 255, 0), 2)\n",
    "                        overlay_image(image, like_img, 50, 100)\n",
    "                    # Victory gesture(fireworks)\n",
    "                    if fingers == [0, 1, 1, 0, 0]:\n",
    "                        for _ in range(5):\n",
    "                            x = random.randint(100, w - 100)\n",
    "                            y = random.randint(50,200)\n",
    "                            fireworks_positions.append((x,y,0))\n",
    "                # Draw Landmarks\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        # Draw fireworks (blinking effect)\n",
    "        new_positions = []\n",
    "        for (x,y,t) in fireworks_positions:\n",
    "            if t < 20:\n",
    "                if t % 3 != 0: #blink effect\n",
    "                    resized_fw = resize_emoji(fireworks_img, width = 100)\n",
    "                    overlay_image(image,resized_fw, x, y-t *5)\n",
    "                new_positions.append((x, y, t+1))\n",
    "        fireworks_positions = new_positions\n",
    "        #show the count\n",
    "        cv2.putText(image, \"Fingers: \" + str(finger_count), (20, 50),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1.5, (158, 0, 0), 3)\n",
    "        #Display window\n",
    "        cv2.imshow(\"Hand Gesture with Count\", image)\n",
    "        out.write(image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3754c94-7e92-4c8c-bfdb-68aa5730fbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca5746-0eb6-494a-9ade-7a2b455d1166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42925bae-fb77-4bc0-96cb-dddb770749d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec895eb-ab8d-4306-b362-fad257504b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838776fd-9718-483d-98e0-0ed9f5fdb87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
